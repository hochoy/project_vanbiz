---
title: "Parsing Vancouver Business Licenses"
author: "David Choy"
date: "2/26/2017"
output: 
  html_document: 
    keep_md: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = 'markdown')
```
![](cityofvan_opendata.png)  

***  

[See repo for a better markdown render of this page](https://github.com/hochoy/project_portfolio2/)  
  

### Main objective  
In this project, we use business licenses from the [City of Vancouver's OpenData portal](http://data.vancouver.ca/datacatalogue/index.htm) to plot vancouver's businesses on a map. Before we do that, the data needs to be cleaned, corrected (if needed) and transformed into geojson format for Mapbox GL JS. Throughout this guide, I will be referring to errors/dirt in the data as "data dirt".
  
### Load R libraries
First, I load the required r libraries for this analysis. Since we are dealing with maps, json files, geocoding and web interaction, we will be needing a lot more libraries than usual.  
  

```{r load_library,warning=FALSE,message=FALSE}
library(jsonlite) # for reading json and writing geojson
library(ggplot2) # for general plotting and sanity check of the data
library(stringr) # for parsing and cleaning strings such as Business Names
library(readr) # for reading and writing .rds files which is a R formatted object file 
library(dplyr) # the god of simple data manipulation
library(ggmap) # plots maps from R code. in this case, I am only using the google geocoding feature
library(RCurl)
library(gridExtra) #arranging multiple plots together
# library(plotly) #plotly bar graph labels are broken
library(knitr) # for knitting the R markdown file into markdown and html
source("~/Developer/project_portfolio2/custom_func.R") # I wrote a set of utility functions for quickly reading/writing tsv files and to play a sound when super-slow functions finish running.
```  
  
### Read in the business license file (json) and having a quick look at the data  

Then, I downloaded the vancouver business licenses from the [City of Vancouver Open Data portal](http://data.vancouver.ca/datacatalogue/businessLicence.htm). I've chosen to use the json format of the file here but csv is also available at the vancouver open data website. After reading the data, I usually add an index column to keep track of rows before doing any manipulation. Additionally, it is a good idea to check the size of a dataset. If there are a million rows in a dataset that should only have 10,000 entries, there is a high chance that the file was not read in correctly.  
  
```{r read}
json_path <- "~/Developer/project_portfolio2/business_licences.json"
vanbiz_raw <- fromJSON(json_path)
vanbiz_df <- vanbiz_raw$features$properties %>%
  mutate(index = 1:nrow(.)) %>% 
  select(index,everything()) 
vanbiz_df %>% nrow() # 61391 companies registered with the City of Vancouver. That's a lot!
```  

####Finding dirt in the data####  

Already, we have stumbled on our first clumps of data dirt. As we can see below:  

1. some businesses do not have a registered address or geocoordinate
2. NumberOfEmployees was read in as a character, not an integer  

```{r}
vanbiz_df %>% str()
```  
  
### Fixing integers that are read as characters  
  
Changing the NumberOfEmployees column from a "character" class back to "integer" class is as simple as using the function `as.integer()`. As can be seen in the previous `str()` output, this error was caused by the presence of oddly-formatted numbers such as "000" or "01".  

```{r fix_integer}
vanbiz_df <- vanbiz_df%>% 
  mutate(NumberOfEmployees = as.integer(NumberOfEmployees)) %>% 
  mutate(Country = sapply(Country, function(x){ifelse(x == "CAN",
                                                      "Canada",
                                                      x)}))
```  

### Filtering the data  

When tackling any big dataset, the first question to ask is if we can focus our analysis at a smaller subset. In this case, I want to find local companies that are likely to hire new graduates this year. Using this as my guide, I chose the following filters:  

1. Keep only businesses with pending or active licenses (can't hire if you're not licensed!)
2. Keep only businesses with more than 10 employees (as they are more likely to hire)  
3. Keep only businesses that have an address in BC  


```{r echo=F,warning=F,message=F}
plot_status <- (vanbiz_df %>% 
  group_by(Status) %>% 
  summarize(n_companies=n()) %>% 
  ungroup() %>% 
  mutate(percent = paste0(round(n_companies/sum(n_companies) * 100,2)," %","\n",n_companies)) %>% 
  ggplot(aes(x=Status,y=n_companies,fill=Status,label=percent)) +
  geom_bar(stat="identity") + geom_text(nudge_y = 2300)+ theme(legend.position="none")) #%>% ggplotly()

plot_employee <- (vanbiz_df %>% 
  mutate(morethan10_employees = (NumberOfEmployees >= 10)) %>% 
  group_by(morethan10_employees) %>% 
  summarize(n_companies=n()) %>% 
  mutate(percent = paste0(round(n_companies/sum(n_companies) * 100,2)," %","\n",n_companies)) %>% 
  ggplot(aes(x=morethan10_employees,y=n_companies,fill=morethan10_employees,label=percent)) +
  geom_bar(stat="identity") + geom_text(nudge_y = -2700) + theme(legend.position="none"))# %>% ggplotly()

plot_province_canada_and_null <- (vanbiz_df %>% 
  group_by(Country,Province) %>% 
  summarize(n_companies=n()) %>% 
  ungroup() %>% 
  mutate(percent = paste0(round(n_companies/sum(n_companies) * 100,2)," %","\n",n_companies)) %>%  
  droplevels() %>%
  filter(Country == "Canada" | is.na(Country)) %>%
  mutate(Province = reorder(Province,desc(n_companies))) %>% 
  ggplot(aes(x=Province,y=n_companies, fill=Province,label=percent)) +
  geom_bar(stat="identity")+ 
    geom_text(nudge_y =  1000) + 
    theme(legend.position="none")) #%>% ggplotly()

plot_province_usa <- vanbiz_df %>%
  group_by(Country,Province) %>%
  summarize(n_companies=n()) %>%
  ungroup() %>%
  mutate(percent = paste0(round(n_companies/sum(n_companies) * 100,2)," %","\n",n_companies)) %>%
  droplevels() %>%
  filter(Country == "USA") %>%
  mutate(Province = reorder(Province,desc(n_companies))) %>% 
  ggplot(aes(x=Province,y=n_companies, fill=Province,label=percent)) +
  geom_bar(stat="identity")+
    geom_text(nudge_y =  2) +
    theme(legend.position="none") 

plot_province_other <- vanbiz_df %>%
  group_by(Country) %>%
  summarize(n_companies=n()) %>%
  ungroup() %>%
  mutate(percent = paste0(round(n_companies/sum(n_companies) * 100,2)," %","\n",n_companies)) %>%
  filter(Country != "Canada" & Country != "USA") %>%
  droplevels() %>%
  mutate(Country = reorder(Country,desc(n_companies))) %>% 
  ggplot(aes(x=Country,y=n_companies, fill=Country,label=percent)) +
  geom_bar(stat="identity")+
    geom_text() +
    theme(legend.position="none")


```  

#### Company status  
```{r fig.width=9,fig.height=4.5,echo=F}
grid.arrange(plot_status,
             plot_employee,
             nrow=1) 
```  

####Companies in Canada  

```{r fig.width=9,fig.height=4.5,echo=F}
plot_province_canada_and_null
```  

####Companies from USA  

```{r fig.width=9,fig.height=4.5,echo=F}
plot_province_usa
```  

####Companies from other countries  

```{r fig.width=9,fig.height=4.5,echo=F}
plot_province_other
```  

```{r echo=F}
vanbiz_valid <- vanbiz_df %>% 
  filter(Province == "BC" | is.na(Province)) %>% 
  filter(NumberOfEmployees >= 10) %>% 
  filter(Status %in% c("Issued","Pending")) %>% 
  filter(!is.na(BusinessName))
n_biz_valid <- nrow(vanbiz_valid) # 6149 businesses that pass our filter
```  

After filtering, what we end up with is a list of `r n_biz_valid` companies with registered BC addresses and more than 10 employees (qualifying it as a Small-to-Medium Enterprise). These are the companies that we will focus on.  

```{r}
vanbiz_valid <- vanbiz_df %>% 
  filter(Province == "BC" | is.na(Province)) %>% 
  filter(NumberOfEmployees >= 10) %>% 
  filter(Status %in% c("Issued","Pending")) %>% 
  filter(!is.na(BusinessName))
nrow(vanbiz_valid) 
```  

```{r echo=F,results='asis'}
kable(vanbiz_df %>% 
        select(BusinessName,Status,BusinessType,House,Street,Province,NumberOfEmployees) %>% 
        filter(NumberOfEmployees >= 10) %>% 
        filter(Province == "BC") %>% 
        head())
```

***

### Check to see if these businesses have a valid coordinate that we can use with Mapbox GL JS

```{r}
vanbiz_latlongcheck <- vanbiz_valid %>% 
  mutate(hascoord = (!is.na(Latitude) & !is.na(Longitude))) %>% 
  mutate(hasaddress = (!is.na(House) & !is.na(Street)))

n_biz_wcoord <- vanbiz_latlongcheck %>% filter(hascoord) %>% nrow() # 5442 biz have coords -> READY
n_biz_nocoord <- vanbiz_latlongcheck %>% filter(!hascoord) %>% nrow() # 707 biz have no coords
n_biz_waddress <- vanbiz_latlongcheck %>% filter(!hascoord) %>% 
  filter(hasaddress) %>% nrow()                       # 665 biz have address -> GEOCODE
n_biz_noaddress <- vanbiz_latlongcheck %>% filter(!hascoord) %>% 
  filter(!hasaddress) %>% nrow()                       # 42 biz have no address -> Google API 
```  

1. `r n_biz_wcoord` businesses have geo coordinates. These are ready to be converted into geojson.  
2. `r n_biz_nocoord` businesses do not have geo coordinates, they will have to be geocoded.  
    + `r n_biz_waddress` of these have addresses, they will be ggmap-geocoded  
    + `r n_biz_noaddress` of these do not have addresses, they will be GooglePlaces-geocoded  

ggmap-geocoding via google's api takes in a query as a full address instead of split into Unit, House number, street number, etc. My early attempts with geocoding failed when zipcodes were included as zipcodes often change or are inaccurate. In the following code chunk, I added one column to house the address query and another column to track if each business was successfully geocoded.

```{r }
# add full address and geocode columns. Needed later
vanbiz_pregeocoded <- vanbiz_latlongcheck %>% 
  mutate(full_address = "not set",
         geocode = "not run")

# write_rds(vanbiz_pregeocoded,"~/Developer/project_portfolio2/vanbiz_pregeocoded.rds")
```


### ggmap-geocoding: Creating a function for geocoding businesses with addresses

While creating a function for geocoding, I created a simple helper function below that could detect whether the geocode was sucessful.

```{r}
vanbiz_pregeocoded <- read_rds("~/Developer/project_portfolio2/vanbiz_pregeocoded.rds")

#helper function
isGeocoded <- function(geocode_list) {
  temp_vec <- vector()
  for (i in 1:length(geocode_list)) {
    temp_vec[i] <- !is.na(geocode_list[[i]]$lon)
  }
  temp_vec
}
```  

The ggmap-geocoding function itself is rather long and has 6 main parts:  

1. The first part filters out businesses that were previously geocoded  
2. The second splits the businesses dataframe into businesses that don't need geocoding (has coord), businesses that have an address and business that have neither.  
3. Because ggmap runs on google's api, there is a limit of 2500 queries per user per day and thus, we have a check for the number of queries remaining.  
4. The fourth is the actual geocoding section and here parts of an address are pasted together to form a full address for querying.  
5. After the "has address" list is geocoded, we check for businesses that failed to geocode.
6. Successful geocoded business enter the "vanbizhasaddress_success" dataframe while businesses that failed to geocode based on address

```{r}
geocode_biz <- function(vanbiz_df) {
  
  # 1. filter for rows that need geocoding work
  vanbiz_todo <- vanbiz_df %>% 
    filter(geocode == "not run")
  
  # 2. filter df for geocoding and google search api
  vanbiz_hascoord <- vanbiz_todo %>% 
    filter(hascoord) %>% 
    mutate(geocode = "has coord")
  vanbiz_hasaddress <- vanbiz_todo %>% 
    filter(!hascoord) %>% 
    filter(hasaddress)
  vanbiz_noaddress <- vanbiz_todo %>% 
    filter(!hascoord) %>% 
    filter(!hasaddress)
  
  # 3. break the function if there are not enough geocoding queries remaining
  if ((nrow(vanbiz_hasaddress) + nrow(vanbiz_noaddress)) > 
      as.integer(str_extract(geocodeQueryCheck(),"[0-9]+"))) {
    print("2500 geocode limit reached")
    break
  }
  
  # 4. geocode vanbiz_hasaddress
  vanbiz_hasaddress <- vanbiz_hasaddress %>% 
    mutate(full_address = paste(House,Street,City,Province,"Canada"),
           geocode = lapply(full_address,
                            function(x) {geocode(x)})) %>% 
    mutate(Latitude = sapply(geocode,function(x){x$lat})) %>% 
    mutate(Longitude = sapply(geocode,function(x){x$lon}))
  
  vanbiz_hasaddress_success <- vanbiz_hasaddress %>% 
    filter(isGeocoded(geocode))
  vanbiz_hasaddress_failed <- vanbiz_hasaddress %>% 
    filter(!isGeocoded(geocode))
  
  # 5. check for failed geocoding
  vanbiz_googlesearch <- vanbiz_noaddress %>% 
    rbind(vanbiz_hasaddress_failed)
  
  #display remaining query
  print(geocodeQueryCheck())
  # 6. final output
  list(vanbiz_hascoord = vanbiz_hascoord,
       vanbiz_hasaddress_success = vanbiz_hasaddress_success,
       vanbiz_googlesearch = vanbiz_googlesearch)
}

# vanbiz_geocoded <- geocode_biz(vanbiz_pregeocoded)
# write_rds(vanbiz_geocoded,"~/Developer/project_portfolio2/vanbiz_geocoded.rds")
```  
  
Installing a [nominatim server/local instance that runs on OpenStreetMap](https://wiki.openstreetmap.org/wiki/Nominatim/Installation) is an alternative to using the `geocode` package or other hosted geocoding API.  

Update: BC now has a publicly available geocoder to try out!  

Google and other hosted APIs (i.e. mapquest) limit searches, geocoding and the use of the data on their servers and thus, is not feasable beyond this demo. However, google also has the Places Library that lets us find places via bizname when the address is not available. For now, we will use a mix of Google geocoding(for address geocoding) and Google Places (for business name geocoding)

### GoogleMapsApi-geocoding: Creating a function for geocoding businesses using business names

Businesses that do not have addresses that could be geocoded require querying via business name. For that, google's API appears to have the highest coverage via their Google Places system that helps businesses register themselves.  

The function below uses the `nearbysearch` API of google. Query requests of this type uses a simple url `"https://maps.googleapis.com/maps/api/place/nearbysearch/json?"` followed by fields such as location, radius, name as well as a mandatory User API key to limit queries. Besides generating a url query, my  function has a randomizer that ensures our requests occur at random intervals. This randomization serves no purpose at the moment as google only requires an API user to limit their rate of query. However, the intention was for it to simulate a human user. The last purpose of this function is to parse the query result and add the desired fields into our original dataframe.    

```{r}
vanbiz_geocoded <- read_rds("~/Developer/project_portfolio2/vanbiz_geocoded.rds")

View(vanbiz_geocoded$vanbiz_hascoord) # 5442 biz have valid coordinates
View(vanbiz_geocoded$vanbiz_hasaddress_success) # 659 biz have addresses that were successfully geocoded
View(vanbiz_geocoded$vanbiz_googlesearch) # 48 have no addresses or have addresses that were NOT sucessfully geocoded

# run google search api on these addresses to get addressses for geocoding
# performed via https://developers.google.com/places/web-service/search
# using 'nearbysearch'

google_maps_search <- function(query_df = vanbiz_geocoded$vanbiz_googlesearch,
                                 searchCenter = "49.253386,-123.130621",
                                 searchRadius = 30000,
                                 api_key = "AIzaSyDL7KVzfaUb-17Ew_cycTG0GoAlf9YammY") {
  
  # parse out a hyperlink to access the Google maps api
  vanbiz_googleplaces <- query_df %>% 
    mutate(link = paste0("https://maps.googleapis.com/maps/api/place/nearbysearch/json?",
                         "location=",searchCenter,
                         "&radius=",searchRadius,
                         "&name=",(BusinessName %>% 
                                     str_trim(side="both") %>% 
                                     str_replace_all("[^[:alnum:] ]"," ") %>% 
                                     str_replace_all(" ","+")),
                         "&key=",api_key))

  googlesearch_results <- data.frame(index = vector(),
                                     goo_lat = vector(),
                                     goo_lng = vector(),
                                     goo_address = vector(),
                                     goo_name = vector())
             
  # loop through all rows to query google maps api
  for (i in 1:nrow(vanbiz_googleplaces)) {
    print(i)
    
    ori_index <- vanbiz_googleplaces$index[i]
    goo_query <- vanbiz_googleplaces$BusinessName[i]
    
    # query the API
    goo_response <- vanbiz_googleplaces$link[i] %>%
      getURL() %>%
      fromJSON()
    
    # parse the results
    if (goo_response$status == "OK" && (!is.na(goo_query) && goo_query != "NA")) {
      goo_result <- goo_response$results[1,]
      #desired fields
      goo_lat <- goo_result$geometry$location$lat
      goo_lng <- goo_result$geometry$location$lng
      goo_address <- goo_result$vicinity
      goo_name <- goo_result$name
    } else {
      goo_lat <- 0
      goo_lng <- 0
      goo_address <- "not found"
      goo_name <- "not found"
    }
    
    # add results to the holder df
    googlesearch_results <- rbind(googlesearch_results,
                                  data.frame(index = as.integer(ori_index),
                                             goo_lat = as.double(as.character(goo_lat)),
                                             goo_lng = as.double(as.character(goo_lng)),
                                             goo_address = as.character(goo_address),
                                             goo_name = as.character(goo_name)))
    # randomize the search rate
    Sys.sleep(runif(1,min = 1.2,max = 2))
  }
  
  # combine the results back to the query_df
  vanbiz_googlesearched_output <- left_join(query_df,
                                            googlesearch_results,
                                            by="index")
  vanbiz_googlesearched_output
}


# vanbiz_googlesearched <- google_maps_search(query_df=vanbiz_geocoded$vanbiz_googlesearch)
# write_rds(vanbiz_googlesearched,
#           path = "~/Developer/project_portfolio2/vanbiz_googlesearched.rds")
```

### Manual inspection of GoogleMapsAPI query results  

More often than not, there are disrepancies between the query result and the actual business information. Through this, I learned that even google is not perfect when it comes to data collection. Thus, it is always important to look at subsamples of the data before producing a final output.  

Below I have included a simple function to query a business name or string if I spot any suspicious google results. Preliminary view of the data shows that some businesses were sufficiently accurate but for simplicity and to save time, I have chosen to abandon the 48 googlesearched results. This leaves
me with the vanbiz_hascoord and vanbiz_hasaddress_success datasets.  

```{r results='asis'}
# Look for any disrepancies between our business name and the google maps search
vanbiz_googlesearched <- read_rds("~/Developer/project_portfolio2/vanbiz_googlesearched.rds")
vanbiz_view <- vanbiz_googlesearched %>% select(BusinessName,goo_name,everything())

#tester function
google_query <- function(query_string) {
  link = paste0("https://maps.googleapis.com/maps/api/place/nearbysearch/json?",
                "location=","49.253386,-123.130621",
                "&radius=",50000,
                "&name=",(query_string %>% 
                  str_trim(side="both") %>% 
                  str_replace_all("[^[:alnum:] ]"," ") %>% 
                  str_replace_all(" ","+")),
                "&key=","AIzaSyDL7KVzfaUb-17Ew_cycTG0GoAlf9YammY")
  print(link)
  link %>% getURL() %>% fromJSON()
}
# abc <- google_query("Karoleena Homes")
kable(head(vanbiz_view))
```

### Producing the final dataframe  

Now that we have done our best to geocode the business entries, it is time to recombine the 2 remaining datasets (the 3rd dataset, vanbiz_googlesearched, was abandoned as it had 48 entries only which were questionable google results). To do that, we have to make sure all our fields/columns match between dataframes. Below, we transfer the google-geocoded latitudes and longitudes into the proper Latitude and Longitude columns.

*Fill in the missing Latitude and Longitude columns of vanbiz_googlesearched with goo_lat and goo_lng. Then, remove the goo_ columns*  

```{r}
vanbiz_geocoded$vanbiz_googlesearched <- vanbiz_googlesearched %>% 
  mutate(Latitude = goo_lat,
         Longitude = goo_lng,
         geocode = "googlesearched") 

# Keep only vanbiz_hascoord and vanbiz_hasaddress_success
# vanbiz_googlesearch & vanbiz_googlesearched (the same 48 hits). 
# Not all addresses resolved nicely.
# combine vanbiz_hascoord and vanbiz_hasaddress_success
```  

Then, we combine the 2 datasets via `rbind()`. We also remove the geocode column as it is a `list`, not as `vector` and that would break the conversion from dataframe to json in the next step.  

```{r results='asis'}
vanbiz_kept <- rbind(vanbiz_geocoded$vanbiz_hascoord,
                     vanbiz_geocoded$vanbiz_hasaddress_success)

nrow(vanbiz_kept) # 6101 businesses

# remove the geocode column which is a list. This would throw errors during geojson_write()
vanbiz_vancouver <- vanbiz_kept %>% 
  select(-geocode)
kable(head(vanbiz_vancouver))
# write_rds(vanbiz_vancouver,
#           "~/Developer/project_portfolio2/vanbiz_vancouver.rds")
# vanbiz_vancouver <- read_rds("~/Developer/project_portfolio2/vanbiz_vancouver.rds")
```  

### Finaly geojson conversion  
I used the tutorial below to convert the dataframe into a functioning geojson file which can be used directly by Mapbox GL JS in a web application. Here is the [link to the tutorial to convert r dataframe to geojson](https://ropensci.org/tutorials/geojsonio_tutorial.html). 

```{r messages=F,warning=F}
suppressPackageStartupMessages(library(rgdal))
suppressPackageStartupMessages(library(geojsonio))

# geojson_json(vanbiz_kept[1:2,], lat = 'Latitude', lon = 'Longitude')
# geojson_write(vanbiz_vancouver, lat = 'Latitude', lon = 'Longitude',
#               file = "~/Developer/project_portfolio2/vanbiz_vancouver.geojson",
#               overwrite = T)
```  

### Final result  

See my [mapbox visualization of Vancouver business licenses](https://hochoy.github.io/project_portfolio2/mapbox.html) using cleaned, filtered and geocoded data.  

***  





